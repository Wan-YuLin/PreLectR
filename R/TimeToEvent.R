#' Time-to-Event Feature Selection with PreLect
#'
#' `PreLectCoxPH` performs feature selection for Cox Proportional Hazards by estimating coefficients based on the specified lambda.
#'
#' @param X        Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param pvl      Numeric vector. The prevalence of each feature, generated by `GetPrevalence`.
#' @param event    Numeric vector. Binary indicator for event status: 1 for event occurrence (e.g., death), and 0 for censored (e.g., alive).
#' @param duration Numeric vector. Duration of follow-up time for each sample.
#' @param lambda   Numeric. Lambda value, the intensity of regularization. Strongly suggested to be determined by the `LambdaTuningCoxPH` process.
#' @param run_echo Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol      Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr       Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha    Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon  Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A list containing:
#' - `coef_table`: A data frame containing the estimated coefficients for each feature.
#' - `loss_value`: Final loss value achieved during training.
#' - `convergence`: Difference between the final and penultimate iterations, indicating convergence level.
#' @export
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' 
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' rownames(X_raw) <- paste0('feat',1:n_features)
#' X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization
#' diagnosis <- c('CRC','CRC','health','CRC','health','CRC','health','health','CRC','CRC')
#' diagnosis <- factor(diagnosis, levels=c('health', 'CRC')) # assign the 'health' is control sample
#' pvlvec <- GetPrevalence(X_raw)
#' 
#' result <- PreLect(X_scaled, pvlvec, diagnosis, lambda=1e-4, task="classification")
#'
PreLectCoxPH <- function(X, pvl, event, duration, lambda,
                         max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8, run_echo=FALSE){
  
  if (is.data.frame(X)) {
    X <- as.matrix(X)
  }
  
  if (is.null(rownames(X))) {
    stop("No feature names provided. Please ensure feature names are set as rownames(X).")
  }
  
  if (ncol(X) != length(event)) {
    stop(paste("Event count mismatch: found", length(event),
               "events but data has", ncol(X_raw), "samples."))
  }
  
  if (ncol(X) != length(duration)) {
    stop(paste("Duration count mismatch: found", length(duration),
               "durations but data has", ncol(X_raw), "samples."))
  }
  
  if (is.data.frame(X)) {
    X <- as.matrix(X)
  }
  
  n_features <- nrow(X)
  
  res <- prelect_cox(t(X), pvl, event, lmbd=lambda, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
  best_w <- res$weights[1:n_features]
  select_df <- data.frame('FeatName'=rownames(X), 'coef'=best_w)
  select_df$tendency <- ifelse(best_w > 0, 'harmful', 'protective')
  select_df$tendency[best_w == 0] <- NA
  return(list('coef_table'=select_df, 'loss_value'=res$loss, 'convergence'=res$diff))
}

#' Automatic Lambda Scanning for Cox Proportional Hazards with PreLect
#'
#' This function scans a range of lambda values from 1e-10 to 0.1, identifying the upper and lower boundaries that represent when lasso starts filtering and when it drops all features. The range is divided into `k` parts for examining lambda values.
#'
#' @param X_scale  Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param X_raw    Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.
#' @param event    Numeric vector. Binary indicator for event status: 1 for event occurrence (e.g., death), and 0 for censored (e.g., alive).
#' @param duration Numeric vector. Duration of follow-up time for each sample.
#' @param step     Integer. The number of intervals for splitting within the upper and lower bounds when examining lambda values (default is 50).
#' @param run_echo Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol      Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr       Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha    Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon  Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A vector for examining log-lambda.
#' @export
#'
AutoScanningCoxPH <- function(X_scale, X_raw, event, duration, step=50, run_echo=FALSE,
                              max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8){
  
  if (is.data.frame(X_scale)) {
    X_scale <- as.matrix(X_scale)
  }
  
  if (is.data.frame(X_raw)) {
    X_raw <- as.matrix(X_raw)
  }
  
  if (!all(dim(X_raw) == dim(X_scale))) {
    stop(paste("Dimension mismatch: raw data has dimensions",
               paste(dim(X_raw), collapse = " x "),
               "but scaled data has dimensions",
               paste(dim(X_scale), collapse = " x ")))
  }
  
  if (ncol(X_raw) != length(event)) {
    stop(paste("Event count mismatch: found", length(Y),
               "events but data has", ncol(X_raw), "samples."))
  }
  
  if (ncol(X_raw) != length(duration)) {
    stop(paste("Duration count mismatch: found", length(Y),
               "duration but data has", ncol(X_raw), "samples."))
  }
  
  arrangement_order <- order(duration, decreasing = F)
  event <- event[arrangement_order]
  X_scale <- X_scale[, arrangement_order]
  X_raw <- X_raw[, arrangement_order]
  
  pvl <- get_prevalence(X_raw)
  n_features <- nrow(X_raw)
  exam_range <- 1/10**seq(10,1)
  select_number <- c()
  pb <- txtProgressBar(min = 0, max = 10, style = 3)
  count <- 0
  for(lmbd in exam_range){
    count <- count + 1
    setTxtProgressBar(pb, count)
    
    exam_res <- prelect_cox(t(X_scale), pvl, event, lmbd=lmbd, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
    best_w <- exam_res$weights[1:n_features]
    select_number <- c(select_number, sum(best_w != 0))
  }
  close(pb)
  
  lower <- NaN
  upper <- 0.1
  for(i in 1:length(exam_range)){
    if(is.nan(lower)){
      if(select_number[i] < n_features*0.9){
        lower <- exam_range[i]
      }
    }
    if(select_number[i] < 1){
      upper <- exam_range[i]
      break
    }
  }
  
  sequence <- seq(log(lower), log(upper), length.out = step)
  return(sequence)
}

#' Lambda Tuning for Cox Proportional Hazards with PreLect
#'
#' This function performs automatic tuning of the lambda parameter. By iterating through a given range of lambda values. For each lambda, the function assesses feature prevalence, calculates various performance metrics, and logs results to output files for further analysis.
#'
#' @param X_scale   Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param X_raw     Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.
#' @param event     Numeric vector. Binary indicator for event status: 1 for event occurrence (e.g., death), and 0 for censored (e.g., alive).
#' @param duration  Numeric vector. Duration of follow-up time for each sample.
#' @param lmbdrange Numeric vector. Examining log-lambda vector, provided form `AutoScanningCoxPH`.
#' @param outpath   Character. The absolute-path of output folder for saving tuning result.
#' @param spl_ratio Numeric. The splits ratio for training part (default is 0.7).
#' @param run_echo  Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter  Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol       Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr        Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha     Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon   Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A list containing two elements:
#' - `TuningResult`: A data frame of metrics for each lambda, including the number of selected features, prevalence, and performance metrics.
#' - `PvlDistSummary`: A data frame summarizing prevalence distribution statistics (min, max, quartiles) for selected features at each lambda.
#' @export
LambdaTuningCoxPH <- function(X_scale, X_raw, event, duration, lmbdrange, outpath, spl_ratio=0.7, run_echo=FALSE,
                              max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8){
  
  if (is.data.frame(X_scale)) {
    X_scale <- as.matrix(X_scale)
  }
  
  if (is.data.frame(X_raw)) {
    X_raw <- as.matrix(X_raw)
  }
  
  if (!all(dim(X_raw) == dim(X_scale))) {
    stop(paste("Dimension mismatch: raw data has dimensions", 
               paste(dim(X_raw), collapse = " x "), 
               "but scaled data has dimensions", 
               paste(dim(X_scale), collapse = " x ")))
  }
  
  if (ncol(X_raw) != length(event)) {
    stop(paste("Found input event with inconsistent numbers of samples:", length(event),  
               ", but data had:", ncol(X_raw)))
  }
  
  if (ncol(X_raw) != length(duration)) {
    stop(paste("Found input duration with inconsistent numbers of samples:", length(duration),  
               ", but data had:", ncol(X_raw)))
  }
  
  if (!dir.exists(outpath)) {
    if (!dir.create(outpath, recursive = TRUE)) {
      stop("Error: Unable to create directory at ", outpath)
    }
  }
  
  n_features <- nrow(X_raw)
  n_samples <- ncol(X_raw)
  n_lambda <- length(lmbdrange)
  
  metrics <- data.frame(matrix(0, n_lambda, 6))
  colnames(metrics) <- c('Feature_number','Percentage', 'Prevalence', 'CI', 'loss_history', 'error_history')
  pvl_dist <- data.frame()
  
  split <- TrainTextSplit(event, spl_ratio)
  X_train <- X_scale[, split$train_idx]
  X_test <- X_scale[, split$test_idx]
  y_train <- event[split$train_idx]
  y_test <- event[split$test_idx]
  
  arrangement_order <- order(duration[split$train_idx], decreasing = F)
  X_train <- X_train[, arrangement_order]
  y_train <- y_train[arrangement_order]
  
  arrangement_order <- order(duration[split$test_idx], decreasing = F)
  X_test <- X_test[, arrangement_order]
  y_test <- y_test[arrangement_order]
  test_duration <- duration[split$test_idx][arrangement_order]
  
  loci_pvl <- get_prevalence(X_raw[, split$train_idx]) + 1e-8
  glob_pvl <- get_prevalence(X_raw)
  pb <- txtProgressBar(min = 0, max = n_lambda, style = 3)
  
  for(i in 1:n_lambda) {
    lambda <- exp(lmbdrange[i])
    res <- prelect_cox(t(X_train), loci_pvl, y_train, lmbd=lambda, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
    best_w <- res$weights[1:n_features]
    selected_p_vec <- ifelse(sum(best_w != 0) > 0, glob_pvl[best_w != 0], 0)
    metrics[i,'Feature_number'] <- sum(best_w != 0)
    metrics[i,'Percentage']     <- sum(best_w != 0)/n_features
    metrics[i,'Prevalence']     <- ifelse(sum(best_w != 0) == 0, 0, median(glob_pvl[best_w != 0]))
    metrics[i,'loss_history']   <- res$loss
    metrics[i,'error_history']  <- res$diff
    metrics[i,'CI'] <- 0
    if(sum(best_w != 0) > 3){
      risk <- exp(t(X_test) %*% as.numeric(res$weights))
      metrics[i,'CI'] <- concordance_index(test_duration, y_test, risk)
    }
    
    pvl_dist_row <- data.frame('llmbd'=log(lambda), 'max'= max(selected_p_vec), 'q3'=quantile(selected_p_vec, 0.75),
                               'q2'=median(selected_p_vec), 'q1'=quantile(selected_p_vec, 0.25), 'min'=min(selected_p_vec))
    pvl_dist <- rbind(pvl_dist, pvl_dist_row)
    setTxtProgressBar(pb, i)
  }
  close(pb)
  metrics$loglmbd <- lmbdrange
  rownames(pvl_dist) <- NULL
  write.csv(metrics, paste0(outpath,'/TuningResult.csv'), quote = F)
  write.csv(pvl_dist, paste0(outpath,'/Pvl_distribution.csv'), quote = F, row.names = FALSE)
  return(list('TuningResult'=metrics, 'PvlDistSummary'=pvl_dist))
}

#' Run LambdaTuningCoxPH in Parallel
#'
#' This function performs `LambdaTuningCoxPH` in parallel to accelerate the tuning process.
#'
#' @param X_scale   Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param X_raw     Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.
#' @param event     Numeric vector. Binary indicator for event status: 1 for event occurrence (e.g., death), and 0 for censored (e.g., alive).
#' @param duration  Numeric vector. Duration of follow-up time for each sample.
#' @param lmbdrange Numeric vector. Examining log-lambda vector, provided form `AutoScanningCoxPH`.
#' @param n_cores   Integer. Number of cores for parallel processing.
#' @param outpath   Character. The absolute-path of output folder for saving tuning result.
#' @param spl_ratio Numeric. The splits ratio for training part (default is 0.7).
#' @param run_echo  Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter  Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol       Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr        Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha     Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon   Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A list containing two elements:
#' - `TuningResult`: A data frame of metrics for each lambda, including the number of selected features, prevalence, and performance metrics.
#' - `PvlDistSummary`: A data frame summarizing prevalence distribution statistics (min, max, quartiles) for selected features at each lambda.
#' @export
#' @importFrom parallel makeCluster stopCluster
#' @importFrom doParallel registerDoParallel
#' @importFrom foreach %dopar% foreach
#' 
LambdaTuningCoxPHParallel <- function(X_scale, X_raw, event, duration, lmbdrange, n_cores, outpath, spl_ratio=0.7, run_echo=FALSE,
                                      max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8){
  
  if (is.data.frame(X_scale)) {
    X_scale <- as.matrix(X_scale)
  }
  
  if (is.data.frame(X_raw)) {
    X_raw <- as.matrix(X_raw)
  }
  
  if (!all(dim(X_raw) == dim(X_scale))) {
    stop(paste("Dimension mismatch: raw data has dimensions", 
               paste(dim(X_raw), collapse = " x "), 
               "but scaled data has dimensions", 
               paste(dim(X_scale), collapse = " x ")))
  }
  
  if (ncol(X_raw) != length(event)) {
    stop(paste("Found input event with inconsistent numbers of samples:", length(event),  
               ", but data had:", ncol(X_raw)))
  }
  
  if (ncol(X_raw) != length(duration)) {
    stop(paste("Found input duration with inconsistent numbers of samples:", length(duration),  
               ", but data had:", ncol(X_raw)))
  }
  
  if (!dir.exists(outpath)) {
    if (!dir.create(outpath, recursive = TRUE)) {
      stop("Error: Unable to create directory at ", outpath)
    }
  }
  
  n_features <- nrow(X_raw)
  n_samples <- ncol(X_raw)
  n_lambda <- length(lmbdrange)
  
  split <- TrainTextSplit(event, spl_ratio)
  X_train <- X_scale[, split$train_idx]
  X_test <- X_scale[, split$test_idx]
  y_train <- event[split$train_idx]
  y_test <- event[split$test_idx]
  
  arrangement_order <- order(duration[split$train_idx], decreasing = F)
  X_train <- X_train[, arrangement_order]
  y_train <- y_train[arrangement_order]
  
  arrangement_order <- order(duration[split$test_idx], decreasing = F)
  X_test <- X_test[, arrangement_order]
  y_test <- y_test[arrangement_order]
  test_duration <- duration[split$test_idx][arrangement_order]
  
  loci_pvl <- get_prevalence(X_raw[, split$train_idx]) + 1e-8
  glob_pvl <- get_prevalence(X_raw)
  
  cl <- makeCluster(n_cores)
  registerDoParallel(cl)
  on.exit(stopCluster(cl))
  
  metrics <- foreach(llambda = lmbdrange, .combine = rbind) %dopar% {
    res <- prelect_cox(t(X_train), loci_pvl, y_train, lmbd=exp(llambda), max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
    best_w <- res$weights[1:n_features]
    selected_p_vec <- c(0)
    for(k in 1:length(best_w)){
      if(best_w[k] != 0){
        selected_p_vec <- c(selected_p_vec, glob_pvl[k])
      }
    }
    
    ci_ <- 0
    if(sum(best_w != 0) > 3){
      risk <- exp(t(X_test) %*% as.numeric(res$weights))
      ci_ <- concordance_index(test_duration, y_test, risk)
    }
    
    data.frame(
      'Feature_number' = sum(best_w != 0),
      'Percentage' =sum(best_w != 0)/n_features,
      'Prevalence' = ifelse(sum(best_w != 0) == 0, 0, median(glob_pvl[best_w != 0])),
      'CI' = ci_,
      'loss_history' = res$loss,
      'error_history' = res$diff,
      'loglmbd' = llambda,
      'llmbd' = llambda,
      'max' = max(selected_p_vec),
      'q3'=quantile(selected_p_vec, 0.75),
      'q2'=median(selected_p_vec),
      'q1'=quantile(selected_p_vec, 0.25),
      'min'=min(selected_p_vec)
    )
  }
  rownames(metrics) <- NULL
  pvl_dist <- metrics[,8:13]
  metrics <- metrics[,1:7]
  write.csv(metrics, paste0(outpath,'/TuningResult.csv'), quote = F)
  write.csv(pvl_dist, paste0(outpath,'/Pvl_distribution.csv'), quote = F, row.names = FALSE)
  return(list('TuningResult'=metrics, 'PvlDistSummary'=pvl_dist))
}