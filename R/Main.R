#' Get Prevalence
#' 
#' Calculate prevalence of each feature.
#'
#' @param X Matrix or DataFrame. Raw count data with samples as rows and features as columns.
#' @return A vector of prevalence for each feature.
#' @export
#' @useDynLib PreLectR, .registration = TRUE
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' prevalence <- GetPrevalence(X_raw)
#' prevalence
#'
GetPrevalence <- function(X){
  if (is.data.frame(X)) {
    X <- as.matrix(X)
  }
  return(get_prevalence(X))
}

#' Data Splitting
#' 
#' Splits data into stratified training and testing sets based on specified proportions for each class.
#'
#' @param labels Vector. Labels for the data.
#' @param ratio  Numeric. The proportion of samples to assign to the training set (default is 0.7).
#' @param task   String. Specifies the type of task: either `classification` or `regression` (default is `classification`).
#' @return A list with two elements: `train_idx` for training indices and `test_idx` for testing indices.
#' @export
#'
TrainTextSplit <- function(labels, ratio = 0.7, task='classification'){
  if(task == 'classification'){
    train_idx_vec <- c()
    test_idx_vec <- c()
    for (class in unique(labels)) {
      class_idx <- which(labels == class)
      class_train_idx <- sample(class_idx, round(length(class_idx) * ratio))
      class_test_idx <- setdiff(class_idx, class_train_idx)
      train_idx_vec <- c(train_idx_vec, class_train_idx)
      test_idx_vec <- c(test_idx_vec, class_test_idx)
    }
    return(list(train_idx = train_idx_vec, test_idx = test_idx_vec))
  }
  if(task == 'regression'){
    n <- length(labels)
    train_idx_vec <- sample(seq(1:n), round(n*ratio))
    test_idx_vec <- seq(1:n)[! seq(1:n) %in% train_idx_vec]
    return(list(train_idx = train_idx_vec, test_idx = test_idx_vec))
  }
}

#' Feature Set Evaluation
#'
#' @param x_train Matrix. Training data with samples as rows and features as columns.
#' @param y_train Numeric vector. Labels for the training data.
#' @param x_test  Matrix. Test data with samples as rows and features as columns.
#' @param y_test  Numeric vector. Labels for the test data.
#' @param best_w  Numeric vector. The feature weights estimated from PreLect, used to select relevant features.
#' @param task    String. Specifies the type of task: either `classification` or `regression`.
#' @return A list containing prediction performance metrics. For classification, it includes `AUC`; for regression, it includes `R2`.
#' @export
#' @importFrom pROC roc auc
#' @importFrom PRROC pr.curve
#' 
evaluation <- function(x_train, y_train, x_test, y_test, best_w, task) {
  selected_features <- which(best_w != 0)

  x_subtrain <- x_train[selected_features, ]
  x_subtest <- x_test[selected_features, ]

  data_df <- as.data.frame(t(x_subtrain))
  data_df$label <- y_train

  vid_df <- as.data.frame(t(x_subtest))
  #vid_df$label <- y_test
  
  if(task == 'classification'){
    model <- glm(label ~ ., data = data_df, family = 'binomial')
    predicted_probs <- predict(model, newdata = vid_df, type = "response")
    roc_curve <- roc(y_test, predicted_probs, levels = c(0,1),direction='<')
    auc_value <- auc(roc_curve)
    return(list(AUC = as.numeric(auc_value)))
  }
  if(task == 'regression'){
    model <- lm(label ~ ., data = data_df)
    predicted_vals <- predict(model, newdata = vid_df)
    
    return(list(R2 = R2(y_test, predicted_vals)))
  }
}

#' PreLect
#'
#' PreLect algorithms, integrating L1 regularization with an inverted prevalence penalty, to select universal feature.
#'
#' @param X        Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param pvl      Numeric vector. The prevalence of each feature, generated by `GetPrevalence`.
#' @param Y        Character or numeric vector. Labels for the data.
#' @param lambda   Numeric. Lambda value, the intensity of regularization. Strongly suggested to be determined by the `LambdaTuning` process.
#' @param task     String. Specifies the type of task: either `classification` or `regression` (default is `classification`).
#' @param run_echo Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol      Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr       Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha    Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon  Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A list containing:
#' - `coef_table`: A data frame containing the estimated coefficients for each feature.
#' - `loss_value`: Final loss value achieved during training.
#' - `convergence`: Difference between the final and penultimate iterations, indicating convergence level.
#' @export
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' 
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' rownames(X_raw) <- paste0('feat',1:n_features)
#' X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization
#' diagnosis <- c('CRC','CRC','health','CRC','health','CRC','health','health','CRC','CRC')
#' diagnosis <- factor(diagnosis, levels=c('health', 'CRC')) # assign 'health' as control sample
#' pvlvec <- GetPrevalence(X_raw)
#' 
#' result <- PreLect(X_scaled, pvlvec, diagnosis, lambda=1e-4, task="classification")
#'
PreLect <- function(X, pvl, Y, lambda, task='classification',
                    max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8, run_echo=FALSE){
  
  if (is.data.frame(X)) {
    X <- as.matrix(X)
  }
  
  if (is.null(rownames(X))) {
    stop("No feature names provided. Please ensure feature names are set as rownames(X).")
  }
  
  if (length(unique(Y)) > 2 & task == 'classification') {
    stop("This solver only supports binary classification. For multi-class classification, use AutoScanningMultiClass.")
  }
  
  if (length(unique(Y)) == 1 & task == 'classification') {
    stop(paste("The provided labels contain only one class :", unique(Y)))
  }
  
  if (ncol(X) != length(Y)) {
    stop(paste("Label count mismatch: found", length(Y),
               "labels but data has", ncol(X_raw), "samples."))
  }
  
  if(!task %in% c('classification','regression')) {
    stop("Invalid task parameter. Choose either 'classification' or 'regression'.")
  }
  
  if(task == 'classification'){
    if(is.null(levels(Y))){
      control_sample <- as.character(sort(Y[1]))
    } else {
      control_sample <- levels(Y)[1]
    }
    y <- ifelse(Y == control_sample, 0, 1)
    case_sample <- as.character(unique(Y)[unique(Y) != control_sample])
  } else if(task == 'regression') {
    y <- Y
  }
  
  n_features <- nrow(X)
  if(task == 'classification'){
    res = prelect_clr(X, pvl, y, lmbd=lambda, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
    best_w = res$weights[1:n_features]
    select_df <- data.frame('FeatName'=rownames(X), 'coef'=best_w)
    select_df$tendency <- ifelse(best_w > 0, case_sample, control_sample)
    select_df$tendency[best_w == 0] <- NA
  }
  if(task == 'regression'){
    res = prelect_reg(X, pvl, y, lmbd=lambda, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
    best_w = res$weights[1:n_features]
    select_df <- data.frame('FeatName'=rownames(X), 'coef'=best_w)
    select_df$tendency <- ifelse(best_w > 0, 'high', 'low')
    select_df$tendency[best_w == 0] <- NA
  }
  
  return(list('coef_table'=select_df, 'loss_value'=res$loss, 'convergence'=res$diff))
}

#' Automatically Lambda Scanning
#'
#' This function scans a range of lambda values from 1e-10 to 0.1, identifying the upper and lower boundaries that represent when lasso starts filtering and when it drops all features. The range is divided into `k` parts for examining lambda values.
#'
#' @param X_scale  Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param X_raw    Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.
#' @param Y        Character or numeric vector. Labels for the data.
#' @param task     String. Specifies the type of task: either `classification` or `regression` (default is `classification`).
#' @param step     Integer. The number of intervals for splitting within the upper and lower bounds when examining lambda values (default is 50).
#' @param run_echo Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol      Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr       Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha    Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon  Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A vector for examining log-lambda.
#' @export
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' 
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization
#' 
#' diagnosis <- c('CRC','CRC','control','CRC','control','CRC','control','control','CRC','CRC')
#' 
#' lrange <- AutoScanning(X_scaled, X_raw, diagnosis, task = "classification")
#' 
#' tuning_res <- LambdaTuning(X_scaled, X_raw, diagnosis, lrange, outpath=getwd())
#' 
#' lmbd_picking <- LambdaDecision(tuning_res$TuningResult, tuning_res$PvlDistSummary)
#' 
#' # optimal lambda
#' lmbd_picking$opt_lmbd
#' 
#' # segmented regression visualization
#' library(patchwork)
#' lmbd_picking$selected_lmbd_plot/lmbd_picking$pvl_plot
#'
AutoScanning <- function(X_scale, X_raw, Y, task='classification', step=50, run_echo=FALSE,
                         max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8){
  
  if (is.data.frame(X_scale)) {
    X_scale <- as.matrix(X_scale)
  }
  
  if (is.data.frame(X_raw)) {
    X_raw <- as.matrix(X_raw)
  }
  
  if (!all(dim(X_raw) == dim(X_scale))) {
    stop(paste("Dimension mismatch: raw data has dimensions",
               paste(dim(X_raw), collapse = " x "),
               "but scaled data has dimensions",
               paste(dim(X_scale), collapse = " x ")))
  }
  
  if (length(unique(Y)) > 2 & task == 'classification') {
    stop("This solver only supports binary classification. For multi-class classification, use AutoScanningMultiClass.")
  }
  
  if (length(unique(Y)) == 1 & task == 'classification') {
    stop(paste("The provided labels contain only one class :", unique(Y)))
  }
  
  if (ncol(X_raw) != length(Y)) {
    stop(paste("Label count mismatch: found", length(Y),
               "labels but data has", ncol(X_raw), "samples."))
  }
  
  if(!task %in% c('classification','regression')) {
    stop("Invalid task parameter. Choose either 'classification' or 'regression'.")
  }
  
  if(task == 'classification'){
    if(is.null(levels(Y))){
      control_sample <- as.character(sort(Y[1]))
    } else {
      control_sample <- levels(Y)[1]
    }
    y <- ifelse(Y == control_sample, 0, 1)
    case_sample <- as.character(unique(Y)[unique(Y) != control_sample])
  } else if(task == 'regression') {
    y <- Y
  }
  
  pvl <- get_prevalence(X_raw)
  n_features <- nrow(X_raw)
  exam_range <- 1/10**seq(10,1)
  select_number <- c()
  pb <- txtProgressBar(min = 0, max = 10, style = 3)
  count <- 0
  for(lmbd in exam_range){
    count <- count + 1
    setTxtProgressBar(pb, count)
    if(task == 'classification'){
      exam_res <- prelect_clr(X_scale, pvl, y, lmbd=lmbd, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon, echo=run_echo)
      best_w <- exam_res$weights[1:n_features]
      select_number <- c(select_number, sum(best_w != 0))
    }
    if(task == 'regression'){
      exam_res <- prelect_reg(X_scale, pvl, y, lmbd=lmbd, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon, echo=run_echo)
      best_w <- exam_res$weights[1:n_features]
      select_number <- c(select_number, sum(best_w != 0))
    }
  }
  close(pb)
  
  lower <- NaN
  upper <- 0.1
  for(i in 1:length(exam_range)){
    if(is.nan(lower)){
      if(select_number[i] < n_features*0.9){
        lower <- exam_range[i]
      }
    }
    if(select_number[i] < 1){
      upper <- exam_range[i]
      break
    }
  }
  
  sequence <- seq(log(lower), log(upper), length.out = step)
  return(sequence)
}

#' Lambda Tuning for Feature Selection
#'
#' This function performs automatic tuning of the lambda parameter. By iterating through a given range of lambda values. For each lambda, the function assesses feature prevalence, calculates various performance metrics, and logs results to output files for further analysis.
#'
#' @param X_scale   Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param X_raw     Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.
#' @param Y         Character or numeric vector. Labels for the data.
#' @param lmbdrange Numeric vector. Examining log-lambda vector, generated by `AutoScanning`.
#' @param outpath   Character. The absolute-path of output folder for saving tuning result.
#' @param task      String. Specifies the type of task: either `classification` or `regression` (default is `classification`).
#' @param spl_ratio Numeric. The splits ratio for training part (default is 0.7).
#' @param run_echo  Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter  Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol       Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr        Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha     Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon   Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A list containing two elements:
#' - `TuningResult`: A data frame of metrics for each lambda, including the number of selected features, prevalence, and performance metrics.
#' - `PvlDistSummary`: A data frame summarizing prevalence distribution statistics (min, max, quartiles) for selected features at each lambda.
#' @export
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' 
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization
#' 
#' diagnosis <- c('CRC','CRC','control','CRC','control','CRC','control','control','CRC','CRC')
#' 
#' lrange <- AutoScanning(X_scaled, X_raw, diagnosis, task = "classification")
#' 
#' tuning_res <- LambdaTuning(X_scaled, X_raw, diagnosis, lrange, outpath=getwd())
#' 
#' lmbd_picking <- LambdaDecision(tuning_res$TuningResult, tuning_res$PvlDistSummary)
#' 
#' # optimal lambda
#' lmbd_picking$opt_lmbd
#' 
#' # segmented regression visualization
#' library(patchwork)
#' lmbd_picking$selected_lmbd_plot/lmbd_picking$pvl_plot
#'
LambdaTuning <- function(X_scale, X_raw, Y, lmbdrange, outpath, task='classification', spl_ratio=0.7, run_echo=FALSE,
                         max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8){
  
  if (is.data.frame(X_scale)) {
    X_scale <- as.matrix(X_scale)
  }
  
  if (is.data.frame(X_raw)) {
    X_raw <- as.matrix(X_raw)
  }
  
  if (!all(dim(X_raw) == dim(X_scale))) {
    stop(paste("Found input data with inconsistent numbers of samples with raw data:", 
               paste(dim(X_raw), collapse = " x "), 
               "but scaled data:", 
               paste(dim(X_scale), collapse = " x ")))
  }
  
  if (length(unique(Y)) > 2 & task == 'classification') {
    stop("This solver only supports binary classification. For multi-class classification, use AutoScanningMultiClass.")
  }
  
  if (length(unique(Y)) == 1 & task == 'classification') {
    stop(paste("The provided labels contain only one class :", unique(Y)))
  }
  
  if (ncol(X_raw) != length(Y)) {
    stop(paste("Label count mismatch: found", length(Y),
               "labels but data has", ncol(X_raw), "samples."))
  }
  
  if(!task %in% c('classification','regression')) {
    stop("Invalid task parameter. Choose either 'classification' or 'regression'.")
  }
  
  if (!dir.exists(outpath)) {
    if (!dir.create(outpath, recursive = TRUE)) {
      stop("Error: Unable to create directory at ", outpath)
    }
  }
  
  if(task == 'classification'){
    if(is.null(levels(Y))){
      control_sample <- as.character(sort(Y[1]))
    } else {
      control_sample <- levels(Y)[1]
    }
    y <- ifelse(Y == control_sample, 0, 1)
    case_sample <- as.character(unique(Y)[unique(Y) != control_sample])
  } else if(task == 'regression') {
    y <- Y
  }
  n_features <- nrow(X_raw)
  n_samples <- ncol(X_raw)
  n_lambda <- length(lmbdrange)
  
  metrics <- data.frame(matrix(0, n_lambda, 6))
  if(task == 'classification'){
    colnames(metrics) <- c('Feature_number','Percentage', 'Prevalence', 'AUC','loss_history', 'error_history')
  }
  if(task == 'regression'){
    colnames(metrics) <- c('Feature_number','Percentage', 'Prevalence', 'R2', 'loss_history', 'error_history')
  }
  
  pvl_dist <- data.frame()
  split <- TrainTextSplit(y, spl_ratio, task)
  X_train <- X_scale[, split$train_idx]
  X_test <- X_scale[, split$test_idx]
  y_train <- y[split$train_idx]
  y_test <- y[split$test_idx]
  loci_pvl <- get_prevalence(X_raw[, split$train_idx]) + 1e-8
  glob_pvl <- get_prevalence(X_raw)
  pb <- txtProgressBar(min = 0, max = n_lambda, style = 3)
  
  for(i in 1:n_lambda) {
    lambda <- exp(lmbdrange[i])
    if(task == 'classification'){
      res <- prelect_clr(X_train, loci_pvl, y_train, lmbd=lambda, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
      best_w <- res$weights[1:n_features]
      selected_p_vec <- c(0)
      for(k in 1:length(best_w)){
        if(best_w[k] != 0){
          selected_p_vec <- c(selected_p_vec, glob_pvl[k])
        }
      }
      metrics[i,'Feature_number'] <- sum(best_w != 0)
      metrics[i,'Percentage']     <- sum(best_w != 0)/n_features
      metrics[i,'Prevalence']     <- ifelse(sum(best_w != 0) == 0, 0, median(glob_pvl[best_w != 0]))
      metrics[i,'loss_history']   <- res$loss
      metrics[i,'error_history']  <- res$diff
      metrics[i,'AUC']  <- 0
      if(sum(best_w != 0) > 3){
        perf <- evaluation(X_train, y_train, X_test, y_test, best_w, task)
        metrics[i,'AUC']  <- perf$AUC
      }
    }
    if(task == 'regression'){
      res <- prelect_reg(X_train, loci_pvl, y_train, lmbd=lambda, max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
      best_w <- res$weights[1:n_features]
      selected_p_vec <- c(0)
      for(k in 1:length(best_w)){
        if(best_w[k] != 0){
          selected_p_vec <- c(selected_p_vec, glob_pvl[k])
        }
      }
      metrics[i,'Feature_number'] <- sum(best_w != 0)
      metrics[i,'Percentage']     <- sum(best_w != 0)/n_features
      metrics[i,'Prevalence']     <- ifelse(sum(best_w != 0) == 0, 0, median(glob_pvl[best_w != 0]))
      metrics[i,'loss_history']   <- res$loss
      metrics[i,'error_history']  <- res$diff
      metrics[i,'R2']  <- 0
      if(sum(best_w != 0) > 3){
        perf <- evaluation(X_train, y_train, X_test, y_test, best_w, task)
        metrics[i,'R2']  <- perf$R2
      }
    }
    pvl_dist_row <- data.frame('llmbd'=log(lambda), 'max'= max(selected_p_vec), 'q3'=quantile(selected_p_vec, 0.75),
                               'q2'=median(selected_p_vec), 'q1'=quantile(selected_p_vec, 0.25), 'min'=min(selected_p_vec))
    pvl_dist <- rbind(pvl_dist, pvl_dist_row)
    
    
    setTxtProgressBar(pb, i)
  }
  close(pb)
  metrics$loglmbd <- lmbdrange
  rownames(pvl_dist) <- NULL
  write.csv(metrics, paste0(outpath,'/TuningResult.csv'), quote = F)
  write.csv(pvl_dist, paste0(outpath,'/Pvl_distribution.csv'), quote = F, row.names = FALSE)
  return(list('TuningResult'=metrics, 'PvlDistSummary'=pvl_dist))
}

#' Run LambdaTuning in Parallel
#' 
#' This function performs Lambda Tuning in parallel to accelerate the tuning process. It leverages parallel processing to evaluate multiple lambda values concurrently.
#' 
#' @param X_scale   Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.
#' @param X_raw     Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.
#' @param Y         Character or numeric vector. Labels for the data.
#' @param lmbdrange Numeric vector. Examining log-lambda vector, generated by `AutoScanning`.
#' @param n_cores   Integer. Number of cores for parallel processing.
#' @param outpath   Character. The absolute-path of output folder for saving tuning result.
#' @param task      String. Specifies the type of task: either `classification` or `regression` (default is `classification`).
#' @param spl_ratio Numeric. The splits ratio for training part (default is 0.7).
#' @param run_echo  Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).
#' @param max_iter  Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).
#' @param tol       Numeric. Tolerance for stopping criteria (default is 1e-4).
#' @param lr        Numeric. Learning rate in RMSprop optimizer (default is 0.001).
#' @param alpha     Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).
#' @param epsilon   Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).
#' @return A list containing two elements:
#' - `TuningResult`: A data frame of metrics for each lambda, including the number of selected features, prevalence, and performance metrics.
#' - `PvlDistSummary`: A data frame summarizing prevalence distribution statistics (min, max, quartiles) for selected features at each lambda.
#' @importFrom parallel makeCluster stopCluster
#' @importFrom doParallel registerDoParallel
#' @importFrom foreach %dopar% foreach
#' @export
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' 
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization
#' 
#' diagnosis <- c('CRC','CRC','control','CRC','control','CRC','control','control','CRC','CRC')
#' 
#' lrange <- AutoScanning(X_scaled, X_raw, diagnosis, task = "classification")
#' 
#' # How many cores usage available
#' available_cores <- parallel::detectCores()
#' available_cores
#' 
#' tuning_res <- LambdaTuningParallel(X_scaled, X_raw, diagnosis, n_cores = available_cores-2, lrange, outpath=getwd())
#' 
#' lmbd_picking <- LambdaDecision(tuning_res$TuningResult, tuning_res$PvlDistSummary)
#' 
#' # optimal lambda
#' lmbd_picking$opt_lmbd
#' 
#' # segmented regression visualization
#' library(patchwork)
#' lmbd_picking$selected_lmbd_plot/lmbd_picking$pvl_plot
#'
LambdaTuningParallel <- function(X_scale, X_raw, Y, lmbdrange, n_cores, outpath, task='classification', spl_ratio=0.7, run_echo=FALSE,
                                 max_iter=10000, tol=1e-4, lr=0.001, alpha=0.9, epsilon=1e-8){
  
  if (is.data.frame(X_scale)) {
    X_scale <- as.matrix(X_scale)
  }
  
  if (is.data.frame(X_raw)) {
    X_raw <- as.matrix(X_raw)
  }
  
  if (!all(dim(X_raw) == dim(X_scale))) {
    stop(paste("Found input data with inconsistent numbers of samples with raw data:", 
               paste(dim(X_raw), collapse = " x "), 
               "but scaled data:", 
               paste(dim(X_scale), collapse = " x ")))
  }
  
  if (length(unique(Y)) > 2 & task == 'classification') {
    stop("This solver only supports binary classification. For multi-class classification, use AutoScanningMultiClass.")
  }
  
  if (length(unique(Y)) == 1 & task == 'classification') {
    stop(paste("The provided labels contain only one class :", unique(Y)))
  }
  
  if (ncol(X_raw) != length(Y)) {
    stop(paste("Label count mismatch: found", length(Y),
               "labels but data has", ncol(X_raw), "samples."))
  }
  
  if(!task %in% c('classification','regression')) {
    stop("Invalid task parameter. Choose either 'classification' or 'regression'.")
  }
  
  if (!dir.exists(outpath)) {
    if (!dir.create(outpath, recursive = TRUE)) {
      stop("Error: Unable to create directory at ", outpath)
    }
  }
  
  if(task == 'classification'){
    if(is.null(levels(Y))){
      control_sample <- as.character(sort(Y[1]))
    } else {
      control_sample <- levels(Y)[1]
    }
    y <- ifelse(Y == control_sample, 0, 1)
    case_sample <- as.character(unique(Y)[unique(Y) != control_sample])
  } else if(task == 'regression') {
    y <- Y
  }
  n_features <- nrow(X_raw)
  n_samples <- ncol(X_raw)
  n_lambda <- length(lmbdrange)
  
  split <- TrainTextSplit(y, spl_ratio, task)
  X_train <- X_scale[, split$train_idx]
  X_test <- X_scale[, split$test_idx]
  y_train <- y[split$train_idx]
  y_test <- y[split$test_idx]
  loci_pvl <- get_prevalence(X_raw[, split$train_idx]) + 1e-8
  glob_pvl <- get_prevalence(X_raw)
  
  cl <- makeCluster(n_cores)
  registerDoParallel(cl)
  on.exit(stopCluster(cl))
  
  if(task == 'classification'){
    metrics <- foreach(llambda = lmbdrange, .combine = rbind) %dopar% {
      res <- prelect_clr(X_train, loci_pvl, y_train, lmbd=exp(llambda), max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
      best_w <- res$weights[1:n_features]
      selected_p_vec <- c(0)
      for(k in 1:length(best_w)){
        if(best_w[k] != 0){
          selected_p_vec <- c(selected_p_vec, glob_pvl[k])
        }
      }
      AUC <- 0
      if(sum(best_w != 0) > 3){
        perf <- evaluation(X_train, y_train, X_test, y_test, best_w, task)
        AUC  <- perf$AUC
      }
      data.frame(
        'Feature_number' = sum(best_w != 0),
        'Percentage' = sum(best_w != 0)/n_features,
        'Prevalence' = ifelse(sum(best_w != 0) == 0, 0, median(glob_pvl[best_w != 0])),
        'AUC' = AUC,
        'loss_history' = res$loss,
        'error_history' = res$diff,
        'loglmbd' = llambda,
        'llmbd' = llambda,
        'max' = max(selected_p_vec),
        'q3'=quantile(selected_p_vec, 0.75),
        'q2'=median(selected_p_vec),
        'q1'=quantile(selected_p_vec, 0.25),
        'min'=min(selected_p_vec)
      )
    }
  }
  if(task == 'regression'){
      metrics <- foreach(llambda = lmbdrange, .combine = rbind) %dopar% {
        res <- prelect_reg(X_train, loci_pvl, y_train, lmbd=exp(llambda), max_iter=max_iter, tol=tol, lr=lr, alpha=alpha, epsilon=epsilon,echo=run_echo)
        best_w <- res$weights[1:n_features]
        selected_p_vec <- c(0)
        for(k in 1:length(best_w)){
          if(best_w[k] != 0){
            selected_p_vec <- c(selected_p_vec, glob_pvl[k])
          }
        }
        R2  <- 0
        if(sum(best_w != 0) > 3){
          perf <- evaluation(X_train, y_train, X_test, y_test, best_w, task)
          R2  <- perf$R2
        }
        
        data.frame(
          'Feature_number' = sum(best_w != 0),
          'Percentage' = sum(best_w != 0)/n_features,
          'Prevalence' = ifelse(sum(best_w != 0) == 0, 0, median(glob_pvl[best_w != 0])),
          'R2' = R2,
          'loss_history' = res$loss,
          'error_history' = res$diff,
          'loglmbd' = llambda,
          'llmbd' = llambda,
          'max' = max(selected_p_vec),
          'q3'=quantile(selected_p_vec, 0.75),
          'q2'=median(selected_p_vec),
          'q1'=quantile(selected_p_vec, 0.25),
          'min'=min(selected_p_vec)
        )
    }
  }
  rownames(metrics) <- NULL
  pvl_dist <- metrics[,8:13]
  metrics <- metrics[,1:7]
  write.csv(metrics, paste0(outpath,'/TuningResult.csv'), quote = F)
  write.csv(pvl_dist, paste0(outpath,'/Pvl_distribution.csv'), quote = F, row.names = FALSE)
  return(list('TuningResult'=metrics, 'PvlDistSummary'=pvl_dist))
}

#' Optimal Lambda Decision
#'
#' Determines the optimal lambda value based on the inflection point of the loss curve, which represents the critical balance where the regularization term begins to outweigh the loss term. This function, `LambdaDecision`, finds the inflection point by segmenting the loss curve into n parts through segmented regression.
#' Segmented regression is implemented using Recursive Partitioning and Regression Trees, selecting the first breakpoint as the optimal lambda.
#' 
#' @param TuningRes  DataFrame. The selected feature profile for each lambda being tested, generated by `LambdaTuning`.
#' @param PvlSummary DataFrame. Prevalence distribution for each lambda being tested, generated by `LambdaTuning`.
#' @param maxdepth   Integer. The maximum depth of the decision tree (default is 5).
#' @param minbucket  Integer. The minimum number of observations in each segment (default is 3).
#' @import rpart
#' @import patchwork 
#' @importFrom ggplot2 ggplot aes geom_line geom_point theme_minimal theme geom_vline geom_errorbar scale_x_log10 scale_y_log10 labs ylim
#' @importFrom scales trans_breaks trans_format math_format
#' @return A list containing three elements:
#' - `opt_lmbd`: The optimal lambda value.
#' - `selected_lmbd_plot`: A plot of the loss values at each lambda, with segmented regression visualized and the optimal lambda marked by a vertical line.
#' - `pvl_plot`: A plot of the prevalence distribution of selected features at each lambda.
#' @export
#' @examples
#' set.seed(42)
#' n_samples <- 10
#' n_features <- 100
#' 
#' X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
#' X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization
#' diagnosis <- c('CRC','CRC','control','CRC','control','CRC','control','control','CRC','CRC')
#' 
#' lrange <- AutoScanning(X_scaled, X_raw, diagnosis, task = "classification")
#' 
#' tuning_res <- LambdaTuning(X_scaled, X_raw, diagnosis, lrange, outpath=getwd())
#' 
#' lmbd_picking <- LambdaDecision(tuning_res$TuningResult, tuning_res$PvlDistSummary)
#' 
#' # optimal lambda
#' lmbd_picking$opt_lmbd
#' 
#' # segmented regression visualization
#' library(patchwork)
#' lmbd_picking$selected_lmbd_plot/lmbd_picking$pvl_plot
#'
LambdaDecision <- function(TuningRes, PvlSummary, maxdepth=5, minbucket=3){
  xs <- TuningRes$loglmbd
  ys <- log(TuningRes$loss_history)
  
  dys <- diff(ys) / diff(xs)
  xs_mid <- (xs[-length(xs)] + xs[-1]) / 2
  
  rgr <- rpart(dys ~ xs_mid, control = rpart.control(maxdepth = maxdepth, minbucket = minbucket))
  dys_dt <- predict(rgr, newdata = data.frame(xs_mid = xs_mid))
  
  change_points <- which(dys_dt != dplyr::lag(dys_dt))
  selected_lambda <- TuningRes$loglmbd[change_points[1]]
  
  break_points <- c(1, change_points, nrow(TuningRes))
  rpax1 <- c()
  rpax2 <- c()
  for(i in break_points){
    rpax1 <- c(rpax1, TuningRes$loglmbd[i])
    rpax2 <- c(rpax2, TuningRes$loss_history[i])
  }
  
  data <- data.frame(lambda = exp(TuningRes$loglmbd), loss = TuningRes$loss_history)
  rpda <- data.frame(ax1 = exp(rpax1), ax2 = rpax2)
  
  p1 <- ggplot(data, aes(x = lambda)) +
    geom_line(aes(y = loss), color = "#33CCFF", linetype = "dashed") +
    geom_point(aes(y = loss), color = "#33CCFF") +
    geom_line(data=rpda, aes(x=ax1, y=ax2, color = "red")) +
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x))) +
    scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x))) +
    labs(x = "lambda", y = "Loss value") + theme_minimal() + 
    theme(legend.position="none") +
    geom_vline(xintercept = exp(selected_lambda), linetype = "dotted", color = "black")
  
  p2 <- ggplot(PvlSummary, aes(x = exp(llmbd))) + geom_point(aes(y = q2*100)) +
    geom_errorbar(aes(ymin = q1*100, ymax = q3*100), width = 0.2) +
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x))) +
    labs(x = "lambda", y = "Prevalence (%)") + theme_minimal() + ylim(1,100)
  
  return(list('opt_lmbd'=exp(selected_lambda), 'selected_lmbd_plot'=p1, 'pvl_plot'=p2))
}

#' Connect the DADA2 Pipeline to PreLect Process
#'
#' A function to perform serial numbering for the sequence table generated by the DADA2 pipeline and save it in a specified folder for use in the PreLect process.
#' 
#' @param seqtab   DADA2 object. Sequence table, generated by `DADA2`.
#' @param taxa     DADA2 object. Taxonomy table, generated by `DADA2`.
#' @param out_path Character. The absolute path of the output folder for saving DADA2 outputs.
#' @return Three files are generated in the specified folder: `ASV_table.txt`, `ASV_taxa_table.txt`, and `ASV.fasta`.
#' @export
#' @examples
#' # .....
#' seqtab <- makeSequenceTable(mergers)
#' seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
#'
#' dim(seqtab.nochim)
#' sum(seqtab.nochim)/sum(seqtab)
#' 
#'  # Generate tracking information for filtering steps
#' getN <- function(x) sum(getUniques(x))
#' track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
#' #If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
#' colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
#' rownames(track) <- sample.names
#' head(track)
#' 
#' # Assign taxonomy
#' taxa <- assignTaxonomy(seqtab.nochim, "~/tax/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
#' taxa <- addSpecies(taxa, "~/tax/silva_species_assignment_v132.fa.gz")
#' 
#' output_path <- '~/dada2_output'
#' DADA2Adapter(seqtab.nochim, taxa, output_path)
#' dir(output_path)
#' 
#' data <- read.csv(paste0(output_path,'/ASV_table.txt'), sep = '\t')
#' taxa <- read.csv(paste0(output_path,'/ASV_taxa_table.txt'), sep = '\t')
#' 
DADA2Adapter <- function(seqtab, taxa, out_path){
  n_ASVs <- ncol(seqtab)
  magnitude <- ceiling(log10(n_ASVs))
  ASVID <- sprintf(paste0("ASV%0", magnitude, "d"), 1:n_ASVs)
  
  ASVseq <- colnames(seqtab)
  colnames(seqtab) <- ASVID
  seqtab <- t(seqtab)
  
  rownames(taxa) <- ASVID[match(rownames(taxa), ASVseq)]
  taxa[is.na(taxa)] <- "unidentified"
  
  fileConn <- file(paste0(out_path,"/ASV.fasta"))
  writeLines(c(rbind(paste0(">", ASVID), ASVseq)), fileConn)
  close(fileConn)
  
  write.table(seqtab,file=paste0(out_path,"/ASV_table.txt"), quote=F, sep="\t", row.names=T)
  write.table(taxa,file=paste0(out_path,"/ASV_taxa_table.txt"), quote=F, sep="\t", row.names=T)
}