% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Main.R
\name{LambdaTuning}
\alias{LambdaTuning}
\title{Lambda Tuning for Feature Selection}
\usage{
LambdaTuning(
  X_scale,
  X_raw,
  Y,
  lmbdrange,
  outpath,
  task = "classification",
  spl_ratio = 0.7,
  run_echo = FALSE,
  max_iter = 10000,
  tol = 1e-04,
  lr = 0.001,
  alpha = 0.9,
  epsilon = 1e-08
)
}
\arguments{
\item{X_scale}{Matrix or DataFrame. Scaled data with samples as rows and features as columns, used for machine learning. If no scaled data is provided, raw count data may be used.}

\item{X_raw}{Matrix or DataFrame. Raw count data with samples as rows and features as columns, used to calculate feature prevalence.}

\item{Y}{Character or numeric vector. Labels for the data.}

\item{lmbdrange}{Numeric vector. Examining log-lambda vector, generated by `AutoScanning`.}

\item{outpath}{Character. The absolute-path of output folder for saving tuning result.}

\item{task}{String. Specifies the type of task: either `classification` or `regression` (default is `classification`).}

\item{spl_ratio}{Numeric. The splits ratio for training part (default is 0.7).}

\item{run_echo}{Logical. If TRUE, prints the training result for each lambda being tested (default is FALSE).}

\item{max_iter}{Integer. Maximum number of iterations taken for the solvers to converge (default is 10000).}

\item{tol}{Numeric. Tolerance for stopping criteria (default is 1e-4).}

\item{lr}{Numeric. Learning rate in RMSprop optimizer (default is 0.001).}

\item{alpha}{Numeric. Smoothing constant in RMSprop optimizer (default is 0.9).}

\item{epsilon}{Numeric. Small constant added to the denominator to improve numerical stability (default is 1e-8).}
}
\value{
A list containing two elements:
- `TuningResult`: A data frame of metrics for each lambda, including the number of selected features, prevalence, and performance metrics.
- `PvlDistSummary`: A data frame summarizing prevalence distribution statistics (min, max, quartiles) for selected features at each lambda.
}
\description{
This function performs automatic tuning of the lambda parameter. By iterating through a given range of lambda values. For each lambda, the function assesses feature prevalence, calculates various performance metrics, and logs results to output files for further analysis.
}
\examples{
set.seed(42)
n_samples <- 10
n_features <- 100

X_raw <- matrix(rnbinom(n_features * n_samples, size = 10, mu = 1), nrow = n_features, ncol = n_samples)
X_scaled <- t(scale(t(X_raw)))  # feature-wise z-standardization

diagnosis <- c('CRC','CRC','control','CRC','control','CRC','control','control','CRC','CRC')

lrange <- AutoScanning(X_scaled, X_raw, diagnosis, task = "classification")

tuning_res <- LambdaTuning(X_scaled, X_raw, diagnosis, lrange, outpath=getwd())

lmbd_picking <- LambdaDecision(tuning_res$TuningResult, tuning_res$PvlDistSummary)
# optimal lambda
lmbd_picking$opt_lmbd

# segmented regression visualization
# library(patchwork)
lmbd_picking$selected_lmbd_plot/lmbd_picking$pvl_plot

}
